{"name":"stm","tagline":"An R Package for the Structural Topic Model","body":"##stm: An R Package for the Structural Topic Model\r\n\r\nWebsite: http://bstewart.github.com/stm\r\n\r\nVignette: [Here](https://github.com/bstewart/stm/blob/master/vignettes/stmVignette.pdf)\r\n\r\nAuthors: [Molly Roberts](http://scholar.harvard.edu/mroberts), [Brandon Stewart](http://scholar.harvard.edu/bstewart) and [Dustin Tingley](http://scholar.harvard.edu/dtingley)\r\n\r\nPlease email all comments/questions to bstewart [AT] fas.harvard.edu\r\n\r\n###Summary\r\n\r\nThis repository contains an early release for the stm package for R.  It implements variational EM algorithms for estimating topic models with covariates in a framework we call the Structural Topic Model (stm). Future releases will be available on CRAN but we are using the repository here to provide a soft release.\r\n\r\nThe package currently includes functionality to:\r\n* ingest and manipulate text data\r\n* estimate Structural Topic Models\r\n* calculate covariate effects on latent topics with uncertainty\r\n* estimate a graph of topic correlations\r\n* create all the plots used in our various papers\r\n\r\n###Other Resources\r\n\r\nHave a large text corpus or need a language we don't provide support for?  See our sister project [txtorg](https://textorg.org)\r\n\r\nPapers on the Structural Topic Model:\r\n* Roberts, Stewart, Tingley, and Airoldi. ``The Structural Topic Model and Applied Social Science.'' *Advances in Neural Information Processing Systems Workshop on Topic Models: Computation, Application, and Evaluation*. 2013. Copy available [here](http://scholar.harvard.edu/files/bstewart/files/stmnips2013.pdf)\r\n* Roberts, Stewart, Tingley, Lucas, Leder-Luis, Gadarian, Albertson, and Rand. ``Structural topic models for open-ended survey responses.'' *American Journal of Political Science*. Forthcoming. Copy available [here](http://scholar.harvard.edu/files/dtingley/files/topicmodelsopenendedexperiments.pdf)\r\n* Lucas, Nielsen, Roberts, Stewart, Storer, and Tingley. ``Computer assisted text analysis for comparative politics.'' Copy available [here](http://scholar.harvard.edu/files/dtingley/files/comparativepoliticstext.pdf)\r\n\r\n### Installation Instructions\r\nAssuming you already have R installed (if not see http://www.r-project.org/), the easiest\r\napproach is to use the devtools package to install directly from github.  First you have \r\nto install devtools using the following code.  Note that you only have to do this once\r\n```  \r\nif(!require(devtools)) install.packages(\"devtools\")\r\n```   \r\nThen you can load the package and use the function `install_github`\r\n\r\n```\r\nlibrary(devtools)\r\ninstall_github(\"bstewart/stm\",dependencies=TRUE)\r\n```\r\n\r\nNote that this will install all the packages suggested and required to run our package.  It may take a few minutes the first time, but this only needs to be done on the first use.  In the future you can update to the most recent development version using the same code. \r\n\r\nYou can also grab the binaries or source files for the latest release here: (https://github.com/bstewart/stm/releases).  Then use `install.packages` with `repos=NULL` so that\r\n```\r\ninstall.packages(filepath, repos = NULL)\r\n```    \r\n\r\n### Getting Started\r\nSee the vignette for several example analyses.  The main function to estimate the model is `stm()` but there are a host of other useful functions.  If you have your documents already converted to term-document matrices you can ingest them using `readCorpus()`.  If you just have raw texts you will want to start with `textProcessor()`.\r\n","google":"<script>   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){   (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),   m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)   })(window,document,'script','//www.google-analytics.com/analytics.js','ga');    ga('create', 'UA-47780762-1', 'github.com');   ga('send', 'pageview');  </script>","note":"Don't delete this file! It's used internally to help with page regeneration."}